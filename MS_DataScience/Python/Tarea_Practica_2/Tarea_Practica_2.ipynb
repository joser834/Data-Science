{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ejercicio** : en data science y programación científica es común necesitar vectores con valores dentro de cierto intervalo, pero con sub-intervalos internos con diference espaciamiento ,por ejemplo:\n",
    "\n",
    "[0.  , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55,\n",
    "       0.56, 0.57, 0.58, 0.59, 0.6 , 0.7 , 0.8 , 0.9 , 1.  ]\n",
    "       \n",
    "El primer sub-intervalo incrementa de 0.1 en 0.1 , el segundo de 0.01 en 0.01 , y el tercero de 0.1 en 0.1 nuevamente.\n",
    "\n",
    "Usando unicamente NumPy crea un vector de este tipo con el nombre xs .\n",
    "\n",
    "**nota**: no es permitido usar ciclos, debe realizarse con operaciones \"vectorizadas\" de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55,\n",
       "       0.56, 0.57, 0.58, 0.59, 0.6 , 0.7 , 0.8 , 0.9 , 1.  ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tu codigo aqui (~ 5 lineas de codigo):\n",
    "vec1 = np.linspace(0,0.5,6,endpoint=True,retstep=False)\n",
    "vec2 = np.linspace(0.51,0.59,9,endpoint=True,retstep=False)\n",
    "vec3 = np.linspace(0.6,1,5,endpoint=True,retstep=False)\n",
    "np.hstack((vec1,vec2,vec3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo aplicado a DS** :  Suavizado de curvas a través de promedios de n-puntos(medias móviles):\n",
    "\n",
    "<img src=\"https://www.luisllamas.es/wp-content/uploads/2017/03/arduino-filtro-media-movil-ventana-5.png\">\n",
    "\n",
    "En el mundo la data comunmente posee \"ruido\" por lo cual muchas veces antes de hacer análisis o modelado se necesita \"suavizar\" las curvas para reducir este ruido, una técnica muy sencilla es  el suavizado por promedio de n-puntos(también llamado media móvil), esto significa que para cada punto Xn obtenemos una versión transformada(suavizada) que consiste en promediar n puntos cercanos a el, por ejemplo para n= 3 tenemos que:\n",
    "\n",
    "$$XS_{n}  =  \\frac{X_{n-1}+X_{n}+X_{n+1}}{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05466055  0.42904816  0.78286898  0.94896083  0.95850976  0.77331017\n",
      "  0.51773954  0.16034118 -0.41629087 -0.74158573 -0.98454146 -0.96978642\n",
      " -0.82000922 -0.565146    0.04768533]\n",
      "[-0.05466055  0.38575219  0.72029266  0.89677986  0.89359359  0.74985316\n",
      "  0.48379696  0.08726329 -0.33251181 -0.71413935 -0.89863787 -0.92477903\n",
      " -0.78498055 -0.44582329  0.04768533]\n"
     ]
    }
   ],
   "source": [
    "# las siguientes 3 lineas generan un conjunto de datos que se comportan segun una onda senoidal pero tienen\n",
    "# ruido por lo cual vamos a suavizar usando promedio de 3 puntos\n",
    "# en este ejercicio los generamos manualmente pero pensemos que son datos que pudieron ser generados con algún\n",
    "# instrumento como un sensor, o bien estar almacenados en una base de datos\n",
    "ruido = 0.1*np.random.randn(15) #el ruido comunmente se debe a aleatoriedad o captura no exacta de info.\n",
    "x = np.linspace(0,2*np.pi,15) + ruido\n",
    "x = np.sin(x)\n",
    "\n",
    "#xs es \"x suavizado\", inicialmente es una copia de x\n",
    "xs =  x.copy()\n",
    "\n",
    "for n in range(1,len(x)-1):\n",
    "    xs[n] = (x[n-1] + x[n] + x[n+1])/3\n",
    "    \n",
    "print(x)\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** En este caso usamos un ciclo  para ejemplificar pero ya hemos mencionado que debemos evitarlos siempre que sea posible y usar operaciones \"vectorizadas\" ya que es mucho mas rápido al utilizar  código pre-compilado de C, en este ejercicio debemos remplazar el calculo de xs para hacerlo de manera \"vectorizada\" y eliminar el ciclo for. \n",
    "\n",
    "**tip**: usar slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "ruido = 0.1*np.random.randn(15) #el ruido comunmente se debe a aleatoriedad o captura no exacta de info.\n",
    "x = np.linspace(0,2*np.pi,15) + ruido\n",
    "x = np.sin(x)\n",
    "\n",
    "#xs es \"x suavizado\", inicialmente es una copia de x\n",
    "xs =  x.copy()\n",
    "\n",
    "for n in range(1,len(x)-1):\n",
    "    xs[n] = (x[n-1] + x[n] + x[n+1])/3\n",
    "\n",
    "#xs_new es la nueva versión de \"x suavizado\"\n",
    "#n_1n es n-1\n",
    "n_1n = np.hstack((x[0],\n",
    "                  x[:-2],\n",
    "                  x[-1]))\n",
    "\n",
    "n = x.copy()\n",
    "\n",
    "#n_1p es n+1\n",
    "n_1p = np.hstack((x[0],\n",
    "                  x[2:],\n",
    "                  x[-1]))\n",
    "\n",
    "xs_new = (n_1n+n+n_1p)/3\n",
    "\n",
    "print(xs-xs_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplos en DS:\n",
    "\n",
    "**1)**\n",
    "En machine learning se necesita una manera de \"evaluar\" nuestros modelos ,en ML del tipo \"supervisado\" para modelos de variables discretas categóricas  usamos  para esto  la \"entropía cruzada\" que mide la diferencia  entre 2 distribuciones de probabilidad,la que nuestro modelo predice vs la real obtenida de datos **ground truth** , una entropía cruzada alta es un modelo de ML malo y una entropía cruzada de 0 es un modelo de ML perfecto.\n",
    "\n",
    "La entropía medida en bits(ojo,no cruzada, solo entropía) se define como \"el promedio de información\"(promedio ponderado) y la información se define se define como el negativo del logaritmo base 2 de la probabilidad . \n",
    "\n",
    "$$I(x) = -log_{2}P(x)$$\n",
    "\n",
    "**Comentario**:La entropía es una medida de \"incerteza\", si un evento puede producir muchos resultados diferentes entonces tenemos una alta incerteza del evento lo cual se traduce a entropía alta.\n",
    "\n",
    "La siguiente función calcula para cierta distribución de probabilidad dada por un vector px la información de cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.]\n",
      "[1. 1.]\n",
      "[-0. inf]\n",
      "[0.00014428]\n",
      "[2.        0.4150375]\n",
      "[2.32192809 2.32192809 2.32192809 2.32192809 2.32192809]\n",
      "[1.32192809 2.32192809 3.32192809 3.32192809 2.32192809]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/galileo_python/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log2\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def calcular_informacion(px):\n",
    "    return np.log2(px)*-1\n",
    "\n",
    "distribucion_prob1 = [1.0]\n",
    "distribucion_prob2 = [0.5,0.5]\n",
    "distribucion_prob3 = [1.0,0.0]\n",
    "distribucion_prob4 = [0.9999]\n",
    "distribucion_prob5 = [0.25,0.75]\n",
    "distribucion_prob6 = [0.2]*5 # ojo estas son listas por lo tanto * la replica, no son arrays de numpy\n",
    "distribucion_prob7 = [0.4,0.2,0.1,0.1,0.2]\n",
    "\n",
    "print(calcular_informacion(distribucion_prob1))\n",
    "print(calcular_informacion(distribucion_prob2))\n",
    "print(calcular_informacion(distribucion_prob3))\n",
    "print(calcular_informacion(distribucion_prob4))\n",
    "print(calcular_informacion(distribucion_prob5))\n",
    "print(calcular_informacion(distribucion_prob6))\n",
    "print(calcular_informacion(distribucion_prob7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** Para calcular la información de una distribución de probabilidad necesitamos calcular el producto entre la información de cada posible x y su probabilidad , cada uno de estos elementos nos indica cuanta incerteza aporta cada x a la entropía de la distribución. Crea una función que calcule esto, debe recibir un vector representando a la dist. de probabilidad y devoler otro vector con el termino de entropía para cada x. Por ejemplo:\n",
    "\n",
    "calcular_entropia([0.25,0.75])\n",
    "\n",
    "Debe resultar en :\n",
    "\n",
    "[0.5    ,    0.31127812]\n",
    "\n",
    "**Nota**: la entropía es la suma sobre estos valores, en este caso no calculamos la entropía,unicamente los termimos de su sumatoria. La entropía es:\n",
    "\n",
    "$$S = -\\sum_i^nP(x_{i})log_{2}P(x_{i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.31127812])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tu codigo aqui (~ 4 lineas de codigo)\n",
    "def calcular_entropia(vec):\n",
    "    S = 0\n",
    "    S = vec*np.log2(vec)*-1\n",
    "    return(S)\n",
    "\n",
    "calcular_entropia([0.25,0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** : se ha determinado también que hay costos asociados a la comunicación y relación con los clientes(llamadas,mensajes electrónicos,etc) y que estos también tienen alta correlación con el monto que estos gastan en su primer més siguiendo el modelo:\n",
    "$$c(x) = (x^{2} + x + log (0.0001x)-\\sqrt{0.54x})/100$$\n",
    "\n",
    "Cree una función para calcular este modelo sobre valores de de gasto de nuevos clientes , y luego cree una función  **ganancia_neta(x,g,c)** donde:\n",
    "* x = vector conteniendo los valores de gasto del primer mes para nuevos clientes.\n",
    "* g = función que estima la ganancia en función de x\n",
    "* c = función que estima el costo en función de x\n",
    "\n",
    "La función realiza el calculo simple **g(x) - c(x)** , ya que es posible que los modelos cambien en el tiempo es común recibir como parámetro el modelo o modelos hijos de un modelo mas grande , en este caso eso se logra recibiendo como parámetro las funciones de ganancia y costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancias [20298.85689469  2574.42504495   330.9752857 ]\n"
     ]
    }
   ],
   "source": [
    "def g(x):\n",
    "    return((np.power(x,3) + 2.0*(np.power(x,2.0))+np.exp(0.0001*x) - np.sqrt(2.0*x))/50)\n",
    "\n",
    "def c(x):\n",
    "    return((np.power(x,2) + x + np.log(0.0001*x) - np.sqrt(0.54*x))/100)\n",
    "\n",
    "def ganancia_neta(x,g,c):\n",
    "    return (g(x)-c(x))\n",
    "\n",
    "gastos = np.array([100,50,25])\n",
    "ganancia = ganancia_neta(gastos,g,c)\n",
    "\n",
    "print(\"Ganancias\",ganancia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aritmetica acumulativa\n",
    "\n",
    "En muchos casos es útil usar sumas o productos acumulativos , por ejemplo:\n",
    "\n",
    "**Ejemplo aplicado** En un datawarehouse se tiene un modelo \"lifetime value\" en el que se almacena de manera acumulativa cuantas ganancias se han percibido a lo largo de la vida de los usuarios, un ETL en Python debe calcularlo en función de un vector que contiene de manera ordenada en el tiempo los ingresos percibidos mensualmente para cierto usuario. Podemos usar la funcion **np.cumsum** para esto, en este ejercicio necesitamos determinar el \"lifetime value\" de cierto usuario en su 6to mes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifetime value: [ 25 175 300 375 475 520 542 572]\n",
      "El valor del usuario a su sexto mes es : 520\n"
     ]
    }
   ],
   "source": [
    "def lifetime_value(ganancias_mensuales):\n",
    "    ## tu codigo aqui(~ 1 linea de codigo):\n",
    "    return(np.cumsum(ganancias_mensuales))\n",
    "\n",
    "# Prueba:\n",
    "ganancias_usuario = np.array([25,150,125,75,100,45,22,30])\n",
    "lifetime_value_usuario = lifetime_value(ganancias_usuario)\n",
    "\n",
    "print(\"Lifetime value:\",lifetime_value_usuario)\n",
    "\n",
    "print(\"El valor del usuario a su sexto mes es :\",lifetime_value_usuario[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** Usando argmax crear una función mode(x) para calcular la moda de un vector x , esta función debe devolver una tupla de 2 elementos de la forma:\n",
    "\n",
    "(valor,conteo)\n",
    "\n",
    "**tip** investigar y auxiliarse de otras funciones de numpy y np.argmax, no olvidar trabajar todo vectorizado, sin ciclos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4,5,6,7,8,9,2,2])\n",
    "def mode(x):\n",
    "    ## tu codigo aqui (~ 3 lineas de codigo):\n",
    "    n = np.bincount(x)\n",
    "    return(np.argmax(n),np.max(n))\n",
    "    \n",
    "print(mode(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** : crear una función para calcular la entropía  de una distribución de probabilidad representada como un vector.\n",
    "$$S = -\\sum_i^nP(x_{i})log_{2}P(x_{i})$$\n",
    "\n",
    "**Nota**: a diferencia del ejercicio anterior donde solo calculamos los términos de la entropía, en este caso  si calculamos el valor completo de la entropía, que como mencionamos es una medida de incerteza en una distribución de probabilidad.\n",
    "\n",
    "**recordatorio**: no usar ciclos solo operaciones vectorizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112781244591328"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropia(vec):\n",
    "    S=0\n",
    "    S = vec*np.log2(vec)*-1\n",
    "    return(sum(S))\n",
    "\n",
    "entropia([0.25,0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: En ML usamos la entropía cruzada como una forma de medir que tan bueno es un modelo de variables discretas a través de comparar la distribución de probabilidad que el modelo produce o predice, vs la distribución de probabilidad real dada por los datos de entrenamiento.\n",
    "\n",
    "Podemos ver el siguiente ejemplo que define la forma en que se calcula la entropía cruzada y nos muestra un caso específico:\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/publishintroductiontodeeplearninginpythonandmatlab1-160502102437/95/introduction-to-deep-learning-in-python-and-matlab-54-638.jpg?cb=1462185644\">\n",
    "\n",
    "En este caso interpretamos así: El problema consiste en un modelo o algoritmo de ML que debe producir un vector de 3 elementos indicando la probabilidad de que ciertos datos X pertenezcan a una de 3 categorías.\n",
    "\n",
    "* El modelo de ML produce un vector que indica que estima un 70% de probabilidad de que se trate de la categoría 0, 20% de probabilidad de que se trate de la categoría 1 y 10% de que se trate de la categoría 2.\n",
    "* Los datos reales nos dicen que se trataba de un caso donde con total certeza se sabe que se trata de la categoría 0\n",
    "* La entropía cruzada(a calcular en el ejercicio) nos indica que tan buena es la estimación del modelo, una EC de 0 es un modelo perfecto(en este caso un modelo que predice 100% de prob para la clase 0)\n",
    "\n",
    "**Nota** \n",
    "* Aun que para calcular la entropía usamos logaritmos en base 2, en ML para calcular la entropía cruzada se usa logaritmo natural ya que con este se cumple el proposito **estimar que tanto se alejan las predicciones del modelo de ML de los datos reales** y es comunmente mas rápido de calcular en la computadora.\n",
    "* Ya que estamos trabajando con vectores que representan distribuciones de probabilidad , podemos toparnos con lo que se conoce como : **sparse vectors**(vectores donde la mayoría de elementos son 0), esto puede producir problemas ya que le logaritmo de 0 no esta definido, tu solución debe tomar en cuenta esto y evitar que devuelva \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(Y,Y_hat):\n",
    "    ##tu codigo aqui (~ 1 lineas de codigo)\n",
    "    return(sum(Y*np.log(Y_hat)*-1))\n",
    "\n",
    "y  = np.array([1.0,0,0])\n",
    "y_hat = np.array([0.7,0.2,0.1])\n",
    "\n",
    "cross_entropy(y,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ejercicio** : crear una función que reciba como parámetro un vector x y calcule su magnitud o norma(euclidiana o L2) ,luego usarla para evaluar 2 vectores que representan los errores generados por 2 modelos de machine learning y concluir cual de los 2 modelos es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795\n",
      "2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "def magnitud(x):\n",
    "    return(np.sqrt(sum(np.power(x,2))))\n",
    "\n",
    "errores_modelo1 = np.array([1,2,1,2])\n",
    "errores_modelo2 = np.array([0,1,1,2])\n",
    "\n",
    "print(magnitud(errores_modelo1))\n",
    "print(magnitud(errores_modelo2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ejercicio** Usando la función del ejercicio anterior, crea otra función normalizar(x) que reciba de parámetro un vector x aplique normalización sobre este, el resultado debe ser un nuevo vector del tamaño de x cuya magnitud es igual a 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0.         0.40824829 0.40824829 0.81649658]\n"
     ]
    }
   ],
   "source": [
    "def normalizar(x):\n",
    "    ## tu codigo aqui (~ 3 linea de codigo)\n",
    "    return(x/magnitud(x))\n",
    "\n",
    "print(magnitud(normalizar(errores_modelo1)))\n",
    "print(normalizar(errores_modelo2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
