{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a XOR Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='XORNeuralNetDiagram.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  0\n",
       "1   0   1  1\n",
       "2   1   0  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame({\n",
    "    'x1': [0, 0, 1, 1],\n",
    "    'x2': [0, 1, 0, 1]\n",
    "})\n",
    "y_train = pd.DataFrame({\n",
    "    'y': [0, 1, 1, 0]\n",
    "})\n",
    "XoriginalCol = X_train.columns\n",
    "pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return(np.maximum([np.zeros_like(x)],[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_der(x):\n",
    "    x[x <= 0] = 0\n",
    "    x[x > 0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identity(x):\n",
    "    return([x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Forward Propagation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagation(x, w, func):\n",
    "    toActivate = np.matmul(x, w)\n",
    "    activation = func(toActivate)\n",
    "    return(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(X_train_in, w, epochs, lr, k):\n",
    "    \n",
    "    act_func = [ReLU, ReLU, Identity]\n",
    "    epoch = 1\n",
    "    errors = []\n",
    "    while epoch <= epochs:        \n",
    "        #print('---------- Forward Propagation ----------')\n",
    "        activation = X_train_in\n",
    "        act_log = [activation]\n",
    "        l=3\n",
    "        for layer in range(l):\n",
    "            if layer >= l-1:\n",
    "                #print('Layer ', layer, '; Shape of inputs: ', activation.shape, sep = '')\n",
    "                #print('Layer ', layer, '; Shape of weight: ', w[layer].shape, sep = '')\n",
    "                #print('Activation function:', act_func[layer])\n",
    "                activation = pd.DataFrame(forwardPropagation(np.array(activation), w[layer], act_func[layer])[0])\n",
    "                activation_log = activation\n",
    "                act_log.append(activation_log)\n",
    "                #print('Layer ', layer, '; Shape of outputs: ', activation.shape, sep = '')\n",
    "            else:\n",
    "                #print('Layer ', layer, '; Shape of inputs: ', activation.shape, sep = '')\n",
    "                #print('Layer ', layer, '; Shape of weight: ', w[layer].shape, sep = '')\n",
    "                #print('Activation function:', act_func[layer])\n",
    "                activation = pd.DataFrame(forwardPropagation(np.array(activation), w[layer], act_func[layer])[0], columns = XoriginalCol)\n",
    "                #print('Layer ', layer, '; Shape of outputs: ', activation.shape, sep = '')\n",
    "                bias = pd.Series(np.ones_like(activation.iloc[:,0]), name = 'bias')\n",
    "                activation = pd.concat([activation, bias], axis = 1)\n",
    "                activation_log = activation\n",
    "                act_log.append(activation_log)\n",
    "                #print('Layer ', layer, '; Shape of outputs + bias: ', activation.shape, sep = '')\n",
    "                \n",
    "        error = pd.DataFrame((activation.iloc[:,0]-y_train.iloc[:,0]))\n",
    "        total_error = np.mean(error.iloc[:,0])\n",
    "        errors.append(total_error)\n",
    "        if epoch%k == 0:\n",
    "            print('Epoch', epoch, '- Total Error:', total_error)\n",
    "        \n",
    "        #print('---------- Backpropagation ----------')\n",
    "        layer = 3\n",
    "        delta = error\n",
    "        while layer >= 1:\n",
    "            prior_activation_w = act_log[layer-1].drop('bias', axis = 1)\n",
    "            prior_activation_b = act_log[layer-1]['bias']\n",
    "\n",
    "            if layer <= 2:\n",
    "                #print('Layer:', layer, ' - Delta Initial shape:', delta.shape)\n",
    "                #print('Layer:', layer, ' - Weights Initial shape:' , ((w[layer][0:len(w[layer])-1]).T).shape)\n",
    "                #print('Layer:', layer, ' - Bias Initial shape:', ((w[layer][len(w[layer])-1:len(w[layer])]).T).shape)\n",
    "                delta = np.matmul(np.array(delta),(w[layer][0:len(w[layer])-1]).T) * ReLU_der(prior_activation_w)\n",
    "            update_w = np.matmul(np.array(prior_activation_w).T, np.array(delta))\n",
    "            update_b = np.matmul(np.array(prior_activation_b).T, np.array(delta))\n",
    "            #print('Layer:', layer, ' - Delta Final shape:', delta.shape)\n",
    "\n",
    "            #Parameters Update\n",
    "            w[layer-1][0:len(w[layer-1])-1] = w[layer-1][0:len(w[layer-1])-1] - lr*(update_w)\n",
    "            w[layer-1][len(w[layer-1])-1:len(w[layer-1])] = w[layer-1][len(w[layer-1])-1:len(w[layer-1])] - lr*(update_b)\n",
    "\n",
    "            layer -= 1\n",
    "        epoch += 1\n",
    "    final_result = np.where(activation>=0.5, 1, 0)\n",
    "    return(act_log, errors, final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arquitecture\n",
    "j = [2,2,1]\n",
    "\n",
    "w=[]\n",
    "b=[]\n",
    "#Weights\n",
    "len_w = [X_train.shape[1]+1, X_train.shape[1]+1, X_train.shape[1]+1]\n",
    "for node in range(len(j)):\n",
    "    w.append(np.random.normal(0, 1, size=(len_w[node],j[node])))\n",
    "\n",
    "#adding bias\n",
    "bias = pd.Series(np.ones_like(X_train['x1']), name = 'bias')\n",
    "X_train_in = pd.concat([X_train, bias], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   x1  x2  bias\n",
       " 0   0   0     1\n",
       " 1   0   1     1\n",
       " 2   1   0     1\n",
       " 3   1   1     1, [array([[ 2.29394625,  0.54694539],\n",
       "         [-0.40257455, -0.76242751],\n",
       "         [-0.96051754, -0.81947304]]), array([[ 0.64963423,  0.47766919],\n",
       "         [ 0.6172231 ,  0.91320493],\n",
       "         [ 1.93143512, -0.20844645]]), array([[ 1.17550381],\n",
       "         [-0.25276806],\n",
       "         [ 0.90065165]])])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_in, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 - Total Error: 0.013132455139208854\n",
      "Epoch 200 - Total Error: 0.011797623503866511\n",
      "Epoch 300 - Total Error: 0.010668818987520284\n",
      "Epoch 400 - Total Error: 0.009726036762820106\n",
      "Epoch 500 - Total Error: 0.008931017175890676\n",
      "Epoch 600 - Total Error: 0.008229014589330397\n",
      "Epoch 700 - Total Error: 0.007745695322840862\n",
      "Epoch 800 - Total Error: 0.007238927203297177\n",
      "Epoch 900 - Total Error: 0.006763865182636067\n",
      "Epoch 1000 - Total Error: 0.006228847161671047\n"
     ]
    }
   ],
   "source": [
    "act_log, errors, final_res = neural_net(\n",
    "    X_train_in,\n",
    "    w,\n",
    "    1000,\n",
    "    1e-2,\n",
    "    100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   x1  x2  bias\n",
       " 0   0   0     1\n",
       " 1   0   1     1\n",
       " 2   1   0     1\n",
       " 3   1   1     1,          x1   x2  bias\n",
       " 0  0.000000  0.0   1.0\n",
       " 1  0.000000  0.0   1.0\n",
       " 2  1.007290  0.0   1.0\n",
       " 3  0.205697  0.0   1.0,          x1        x2  bias\n",
       " 0  1.582251  0.000000   1.0\n",
       " 1  1.582251  0.000000   1.0\n",
       " 2  1.884892  0.272705   1.0\n",
       " 3  1.644053  0.000000   1.0,           0\n",
       " 0  0.434471\n",
       " 1  0.434471\n",
       " 2  0.705232\n",
       " 3  0.450741]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12193d780>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
